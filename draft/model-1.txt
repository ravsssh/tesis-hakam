# setup package dan figure styling

# data gathering and preprocessing (load csv that source from bloomberg/ojk/bi/bps)

# check data type and missing values per column

============================================================
DATA TYPES & MISSING VALUES
============================================================
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 121 entries, 0 to 120
Data columns (total 7 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   Date                 121 non-null    object 
 1   IHSG                 121 non-null    float64
 2   Inflation Rate YoY   121 non-null    float64
 3   Money Supply M2 YoY  121 non-null    float64
 4   USDIDR               121 non-null    int64  
 5   BI Interest Rate     121 non-null    object 
 6   npl_ratio            121 non-null    object 
dtypes: float64(3), int64(1), object(3)
memory usage: 6.7+ KB

============================================================
MISSING VALUES PER COLUMN
============================================================
Date                   0
IHSG                   0
Inflation Rate YoY     0
Money Supply M2 YoY    0
USDIDR                 0
BI Interest Rate       0
npl_ratio              0
dtype: int64

# create date index, replace percentage to float

============================================================
CLEANED DATA
============================================================
Date Range: 2015-01-31 00:00:00 to 2025-01-31 00:00:00
Total Months: 121

Data Types after cleaning:
Date             datetime64[ns]
IHSG                    float64
Inflation_YoY           float64
M2_YoY                  float64
USDIDR                    int64
BI_Rate                 float64
NPL_Ratio               float64
dtype: object

# descriptive statistics

============================================================
DESCRIPTIVE STATISTICS(table attached as a picture)
============================================================
Date	IHSG	Inflation_YoY	M2_YoY	USDIDR	BI_Rate	NPL_Ratio
count	121	121.00	121.00	121.00	121.00	121.00	121.00
mean	2020-01-30 02:58:30	6077.38	3.36	8.81	14363.80	5.25	2.77
min	2015-01-31 00:00:00	4223.91	0.76	3.35	12755.00	3.50	2.08
25%	2017-07-31 00:00:00	5386.69	2.48	6.77	13655.00	4.25	2.52
50%	2020-01-31 00:00:00	6056.12	3.18	8.18	14273.00	5.25	2.76
75%	2022-07-31 00:00:00	6843.24	3.83	10.53	14903.00	6.00	3.05
max	2025-01-31 00:00:00	7670.73	7.26	16.26	16375.00	7.75	3.35
std	NaN	850.61	1.49	2.74	895.79	1.24	0.32

# eda

ihsg 10 year line figure
macroeconomics variable 10 year line figure
correlation matrix ihsg and macroeconomics variables
âœ… Figure saved: model1-figure/correlation_matrix.png (300 DPI)

============================================================
CORRELATION WITH IHSG(attached as a picture)
============================================================
USDIDR          : +0.6227 (Moderate â†‘ Positive)
BI_Rate         : -0.2353 (Weak â†“ Negative)
Inflation_YoY   : -0.2740 (Weak â†“ Negative)
M2_YoY          : -0.3763 (Weak â†“ Negative)
NPL_Ratio       : -0.4360 (Moderate â†“ Negative)

# create darts timeseries objects

ihsg series (attached as a picture)
covar series (attached as a picture)

DARTS TIMESERIES
============================================================
Target Series (IHSG):
  - Start: 2015-01-31 00:00:00
  - End: 2025-01-31 00:00:00
  - Length: 121 time steps
  - Frequency: <MonthEnd>

Covariates:
  - Components: ['Inflation_YoY', 'M2_YoY', 'USDIDR', 'BI_Rate', 'NPL_Ratio']
  - Length: 121 time steps

# split train test 80:20 
(attached as a picture)
# normalization (minmaxscaler -1,1)

# output chunk lenght 1, parameter grid

OUTPUT_CHUNK_LENGTH = 1

# hyperparameter tuning gridsearch

param_grid = {
    'lags': [1, 3, 6, 12],
    'lags_past_covariates': [1, 3, 6, 12],       
    'n_estimators': [50, 100, 200],           
    'max_depth': [3, 5, 7, None],
    'max_features': [None, 'sqrt', 'log2'],
    'bootstrap': [True, False],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],        
}
    
print("\nGridSearch Parameters:")
for param, values in param_grid.items():
    print(f"  {param}: {values}")

total_combinations = 1
for values in param_grid.values():
    total_combinations *= len(values)
print(f"\nTotal combinations to evaluate: {total_combinations}")


# train random forest model
best parameter:
============================================================
GRIDSEARCH RESULTS
============================================================
Best MAPE Score: 15.9250%

Best Hyperparameters:
  lags: 3
  lags_past_covariates: 3
  n_estimators: 100
  max_depth: 5
  max_features: None
  bootstrap: True
  min_samples_split: 2
  min_samples_leaf: 2

# create forecast

# model performance metrics

============================================================
MODEL PERFORMANCE METRICS (Original Scale)
============================================================
RMSE    : 277.6745
MAE     : 222.1677
MAPE    : 3.0925
sMAPE   : 3.1312
RÂ²      : -0.0881

# forecast vs actual

[Figure]

======================================================================
FORECAST SUMMARY STATISTICS
======================================================================
Test Period:        January 2023 to January 2025
Number of Points:   25

Actual IHSG:
  Mean:             7081.69
  Min:              6633.26
  Max:              7670.73
  Std Dev:          266.19

Forecast IHSG:
  Mean:             6997.72
  Min:              6979.46
  Max:              7010.30
  Std Dev:          7.87

Prediction Errors:
  Mean Error:       83.96 points
  Mean Abs Error:   222.17 points
  Max Overest:      -360.46 points
  Max Underest:     665.79 points

# SHAP explainer analysis

[Figure]

======================================================================
EXTRACTING SHAP VALUES FOR ANALYSIS
======================================================================
Explanation TimeSeries shape: (23, 18)
Feature values shape: (23, 18)
Feature names: Index(['IHSG_target_lag-3', 'IHSG_target_lag-2', 'IHSG_target_lag-1',
       'Inflation_YoY_pastcov_lag-3', 'M2_YoY_pastcov_lag-3',
       'USDIDR_pastcov_lag-3', 'BI_Rate_pastcov_lag-3',
       'NPL_Ratio_pastcov_lag-3', 'Inflation_YoY_pastcov_lag-2',
       'M2_YoY_pastcov_lag-2', 'USDIDR_pastcov_lag-2', 'BI_Rate_pastcov_lag-2',
       'NPL_Ratio_pastcov_lag-2', 'Inflation_YoY_pastcov_lag-1',
       'M2_YoY_pastcov_lag-1', 'USDIDR_pastcov_lag-1', 'BI_Rate_pastcov_lag-1',
       'NPL_Ratio_pastcov_lag-1'],
      dtype='object')

Total features: 18

======================================================================
TOP 15 MOST IMPORTANT FEATURES (by Mean |SHAP|)
======================================================================
                    Feature  Mean_Abs_SHAP
          IHSG_target_lag-1       0.720058
          IHSG_target_lag-2       0.043895
       USDIDR_pastcov_lag-1       0.023234
    NPL_Ratio_pastcov_lag-3       0.014380
          IHSG_target_lag-3       0.009924
    NPL_Ratio_pastcov_lag-2       0.007144
       M2_YoY_pastcov_lag-3       0.006475
      BI_Rate_pastcov_lag-3       0.004545
       USDIDR_pastcov_lag-3       0.002924
Inflation_YoY_pastcov_lag-3       0.002909
       M2_YoY_pastcov_lag-2       0.002202
      BI_Rate_pastcov_lag-1       0.001905
Inflation_YoY_pastcov_lag-2       0.001746
       USDIDR_pastcov_lag-2       0.001315
Inflation_YoY_pastcov_lag-1       0.001262

======================================================================
FEATURE IMPORTANCE BY CATEGORY (Aggregated)
======================================================================
IHSG_Lags           :   0.7739 (91.42%) - 3 features
USD/IDR             :   0.0275 ( 3.25%) - 3 features
NPL_Ratio           :   0.0223 ( 2.63%) - 3 features
M2_YoY              :   0.0097 ( 1.14%) - 3 features
BI_Rate             :   0.0073 ( 0.86%) - 3 features
Inflation_YoY       :   0.0059 ( 0.70%) - 3 features

======================================================================
DETAILED STATISTICS BY COVARIATE TYPE
======================================================================

IHSG_Lags:
  Total importance: 0.7739
  Number of lags:   3
  Mean per lag:     0.2580
  Top lags:
    - IHSG_target_lag-1                        : 0.7201
    - IHSG_target_lag-2                        : 0.0439
    - IHSG_target_lag-3                        : 0.0099

USD/IDR:
  Total importance: 0.0275
  Number of lags:   3
  Mean per lag:     0.0092
  Top lags:
    - USDIDR_pastcov_lag-1                     : 0.0232
    - USDIDR_pastcov_lag-3                     : 0.0029
    - USDIDR_pastcov_lag-2                     : 0.0013

NPL_Ratio:
  Total importance: 0.0223
  Number of lags:   3
  Mean per lag:     0.0074
  Top lags:
    - NPL_Ratio_pastcov_lag-3                  : 0.0144
    - NPL_Ratio_pastcov_lag-2                  : 0.0071
    - NPL_Ratio_pastcov_lag-1                  : 0.0007

M2_YoY:
  Total importance: 0.0097
  Number of lags:   3
  Mean per lag:     0.0032
  Top lags:
    - M2_YoY_pastcov_lag-3                     : 0.0065
    - M2_YoY_pastcov_lag-2                     : 0.0022
    - M2_YoY_pastcov_lag-1                     : 0.0010

BI_Rate:
  Total importance: 0.0073
  Number of lags:   3
  Mean per lag:     0.0024
  Top lags:
    - BI_Rate_pastcov_lag-3                    : 0.0045
    - BI_Rate_pastcov_lag-1                    : 0.0019
    - BI_Rate_pastcov_lag-2                    : 0.0008

Inflation_YoY:
  Total importance: 0.0059
  Number of lags:   3
  Mean per lag:     0.0020
  Top lags:
    - Inflation_YoY_pastcov_lag-3              : 0.0029
    - Inflation_YoY_pastcov_lag-2              : 0.0017
    - Inflation_YoY_pastcov_lag-1              : 0.0013

======================================================================
RESULTS SAVED
======================================================================
âœ“ shap_feature_importance.csv
âœ“ shap_category_importance.csv
âœ“ shap_values_timeseries.csv
âœ“ feature_values_timeseries.csv

======================================================================
SHAP ANALYSIS SUMMARY REPORT
======================================================================

Model Configuration:
  Lags (target):           3
  Lags (past covariates):  3
  Total features:          18

Data:
  Explainable timestamps:  23
  Test period:             Jan 2023 to Nov 2024

Top 5 Most Important Features:
  1. IHSG_target_lag-1                        : 0.7201 (IHSG_Lags)
  2. IHSG_target_lag-2                        : 0.0439 (IHSG_Lags)
  3. USDIDR_pastcov_lag-1                     : 0.0232 (USD/IDR)
  4. NPL_Ratio_pastcov_lag-3                  : 0.0144 (NPL_Ratio)
  5. IHSG_target_lag-3                        : 0.0099 (IHSG_Lags)

Category Ranking:
  1. IHSG_Lags            : 91.42%
  2. USD/IDR              :  3.25%
  3. NPL_Ratio            :  2.63%
  4. M2_YoY               :  1.14%
  5. BI_Rate              :  0.86%
  6. Inflation_YoY        :  0.70%

======================================================================
SHAP ANALYSIS COMPLETE!
======================================================================

# random forest summary

======================================================================
HASIL PENELITIAN MODEL 1: IHSG DENGAN VARIABEL MAKROEKONOMI
======================================================================

ðŸ“Š DATA:
   â€¢ Periode Data     : January 2015 - January 2025
   â€¢ Total Observasi  : 121 bulan
   â€¢ Train/Test Split : 80% / 20%

ðŸŽ¯ TARGET:
   â€¢ Variabel Target  : IHSG (Indeks Harga Saham Gabungan)

ðŸ“ˆ COVARIATES (Variabel Makroekonomi):
   1. Inflation_YoY
   2. M2_YoY
   3. USDIDR
   4. BI_Rate
   5. NPL_Ratio

âš™ï¸ BEST HYPERPARAMETERS (via GridSearch):
   â€¢ lags: 6
   â€¢ lags_past_covariates: 3
   â€¢ n_estimators: 200
   â€¢ max_depth: 5
   â€¢ max_features: None
   â€¢ bootstrap: True
   â€¢ min_samples_split: 5
   â€¢ min_samples_leaf: 4

ðŸ“ MODEL PERFORMANCE:
   â€¢ MAPE  : 1.1443%
   â€¢ RMSE  : 105.7583
   â€¢ MAE   : 81.9661
   â€¢ RÂ²    : 0.8422

ðŸ” FEATURE IMPORTANCE (SHAP - Top 3):
   1. IHSG: 77.61%
   2. NPL_Ratio: 11.57%
   3. Inflation_YoY: 4.22%

======================================================================
Source: Author's calculation, 2025
======================================================================

setelah ini xgboost dengan tahap yang sama seperti random forest

#xgboost parameter

from darts.models import XGBModel

param_grid_xgb = {
    'lags': [1, 3, 6, 12],
    'lags_past_covariates': [1, 3, 6, 12],       
    'n_estimators': [50, 100, 200],           
    'max_depth': [3, 5, 7, None],
    'learning_rate': [0.01, 0.05, 0.1],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
}

#train model with best parameter

============================================================
GRIDSEARCH RESULTS
============================================================
Best MAPE Score: 15.7613%

Best Hyperparameters:
  lags: 6
  lags_past_covariates: 1
  n_estimators: 200
  max_depth: 3
  learning_rate: 0.1
  subsample: 1.0
  colsample_bytree: 0.8

#xgboost model result
======================================================================
XGBOOST MODEL PERFORMANCE METRICS (Original Scale)
======================================================================
RMSE    :     310.95 points
MAE     :     248.30 points
MAPE    :     3.4242%
sMAPE   :     3.5098%
RÂ²      :    -0.3645

Average IHSG in test period: 7081.69
RMSE as % of avg IHSG: 4.39%
MAE as % of avg IHSG:  3.51%

======================================================================
DIRECTIONAL ACCURACY ANALYSIS
======================================================================
Directional Accuracy: 45.83%
(Baseline random guess: 50%)
Correct predictions: 11/24

======================================================================
MODEL COMPARISON: XGBoost vs Random Forest
======================================================================
             Metric  Random Forest    XGBoost Winner
           MAPE (%)       3.092538   3.424164     RF
      RMSE (points)     277.674516 310.946642     RF
       MAE (points)     222.167742 248.299796     RF
          sMAPE (%)       3.131234   3.509817     RF
                 RÂ²      -0.088134  -0.364527     RF
Directional Acc (%)      58.333333  45.833333     RF

ðŸ“Š Score: RF: 6 | XGB: 0 | Tie: 0
ðŸ† Overall Winner: Random Forest

======================================================================
GENERATING VISUALIZATIONS
======================================================================

#result
======================================================================
HASIL PENELITIAN MODEL 1: IHSG DENGAN VARIABEL MAKROEKONOMI
======================================================================

ðŸ“Š DATA:
   â€¢ Periode Data     : January 2015 - January 2025
   â€¢ Total Observasi  : 121 bulan
   â€¢ Train/Test Split : 80% / 20%
   â€¢ Train Period     : January 2015 - December 2022 (96 obs)
   â€¢ Test Period      : January 2023 - January 2025 (25 obs)

ðŸŽ¯ TARGET:
   â€¢ Variabel Target  : IHSG (Indeks Harga Saham Gabungan)

ðŸ“ˆ COVARIATES (Variabel Makroekonomi):
   1. Inflation_YoY
   2. M2_YoY
   3. USDIDR
   4. BI_Rate
   5. NPL_Ratio

ðŸ¤– MODEL COMPARISON:
======================================================================
Metric                      Random Forest         XGBoost     Winner
----------------------------------------------------------------------
MAPE (%)                           3.0925          3.4242         RF
RMSE (points)                      277.67          310.95         RF
MAE (points)                       222.17          248.30         RF
RÂ²                                -0.0881         -0.3645         RF
Directional Acc (%)                 58.33           45.83         RF

ðŸ† BEST MODEL: Random Forest
   â€¢ MAPE: 3.0925%
   â€¢ RÂ²: -0.0881

âš™ï¸ BEST HYPERPARAMETERS:

Random Forest:
   â€¢ lags                     : 3
   â€¢ lags_past_covariates     : 3
   â€¢ n_estimators             : 100
   â€¢ max_depth                : 5
   â€¢ max_features             : None
   â€¢ bootstrap                : True
   â€¢ min_samples_split        : 2
   â€¢ min_samples_leaf         : 2

XGBoost:
   â€¢ lags                     : 6
   â€¢ lags_past_covariates     : 1
   â€¢ n_estimators             : 200
   â€¢ max_depth                : 3
   â€¢ learning_rate            : 0.1
   â€¢ subsample                : 1.0
   â€¢ colsample_bytree         : 0.8

ðŸ” FEATURE IMPORTANCE (SHAP - Random Forest):

   Top 5 Most Important Features:
   1. IHSG_target_lag-1                        : 85.07% [IHSG_Lags]
   2. IHSG_target_lag-2                        :  5.19% [IHSG_Lags]
   3. USDIDR_pastcov_lag-1                     :  2.74% [USD/IDR]
   4. NPL_Ratio_pastcov_lag-3                  :  1.70% [NPL_Ratio]
   5. IHSG_target_lag-3                        :  1.17% [IHSG_Lags]

   Category Ranking:
   1. IHSG_Lags            :  91.42%
   2. USD/IDR              :   3.25%
   3. NPL_Ratio            :   2.63%
   4. M2_YoY               :   1.14%
   5. BI_Rate              :   0.86%
   6. Inflation_YoY        :   0.70%

ðŸ’¡ KEY FINDINGS:
   1. Random Forest outperforms with 3.09% MAPE
   2. Both models achieve >50% directional accuracy (RF: 58.3%, XGB: 45.8%)
   3. IHSG_Lags is the most influential category
   4. Model explains -8.8% of IHSG variance

======================================================================
Best Model: Random Forest
Horizon: 1 month ahead forecast
Source: Author's calculation, 2025
======================================================================
